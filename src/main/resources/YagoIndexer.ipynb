{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import org.apache.spark.sql.Row\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "import org.graphframes._  \n",
    "\n",
    "def readRdfDf(sc: org.apache.spark.SparkContext, filename: String) = {\n",
    "    val r = sc.textFile(filename).map(_.split(\"\\t\"))\n",
    "    val v = r.map(_ (1)).union(r.map(_ (3))).distinct.zipWithIndex.map(\n",
    "\n",
    "      x => Row(x._2, x._1))\n",
    "    // We must have an \"id\" column in the vertices DataFrame;\n",
    "    // everything else is just properties we assign to the vertices\n",
    "    val stv = StructType(StructField(\"id\", LongType) ::\n",
    "      StructField(\"attr\", StringType) :: Nil)\n",
    "    val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n",
    "    val vdf = sqlContext.createDataFrame(v, stv)\n",
    "    vdf.createOrReplaceTempView(\"v\")\n",
    "    val str = StructType(StructField(\"rdfId\", StringType) ::\n",
    "      StructField(\"subject\", StringType) ::\n",
    "      StructField(\"predicate\", StringType) ::\n",
    "      StructField(\"object\", StringType) :: Nil)\n",
    "    sqlContext.createDataFrame(r.map(Row.fromSeq(_)), str)\n",
    "      .createOrReplaceTempView(\"r\")\n",
    "    // We must have an \"src\" and \"dst\" columns in the edges DataFrame;\n",
    "    // everything else is just properties we assign to the edges\n",
    "    val edf = sqlContext.sql(\"SELECT vsubject.id AS src, vobject.id AS dst, predicate AS attr FROM   r JOIN   v AS vsubject  ON   subject=vsubject.attr JOIN   v AS vobject  ON   object=vobject.attr\")\n",
    "    GraphFrame(vdf, edf)\n",
    "\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                  an|               score|\n",
      "+--------------------+--------------------+\n",
      "|  [7661,<Plato>,102]| 3.822406412297308E7|\n",
      "|[10645,<Aristotle...|3.2961326121938106E7|\n",
      "|[4958,<Immanuel_K...| 2.644528437535423E7|\n",
      "|[2961,<Georg_Wilh...|2.1092802441273782E7|\n",
      "|[9302,<Baruch_Spi...|1.4513392385496272E7|\n",
      "|[12213,<Ren?_Desc...|1.2407118036818413E7|\n",
      "|[12656,<Johann_Wo...|1.0109121178397963E7|\n",
      "|[11891,<Jean-Jacq...|   9081581.748842742|\n",
      "|[11611,<Gottfried...|   7146037.710399863|\n",
      "|[2025,<Friedrich_...|   6896198.740526293|\n",
      "|[1082,<William_Sh...|  4166025.6401630896|\n",
      "|[11030,<Adam_Smit...|  4100900.9763424927|\n",
      "|[1121,<John_Locke...|   3868447.819527024|\n",
      "|[1566,<Heraclitus...|  3616900.3025887734|\n",
      "|[3746,<Karl_Marx>...|   3575419.671920321|\n",
      "|[10950,<S?ren_Kie...|   3143375.914849735|\n",
      "|[7320,<David_Hume...|  3122089.3473657905|\n",
      "|[8538,<Arthur_Sch...|   2978239.727690162|\n",
      "|[3186,<Ibn_Tufail...|   2234249.031615453|\n",
      "|[8265,<Epicurus>,24]|  1812594.4073720106|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val file = \"/data/yagoFactInfluence.tsv\"\n",
    "val in = readRdfDf(sc, file)\n",
    "    in.edges.createOrReplaceTempView(\"e\")\n",
    "    in.vertices.createOrReplaceTempView(\"v\")\n",
    "    val in2 = GraphFrame(in.vertices.sqlContext.sql(\n",
    "      \"SELECT v.id,\" +\n",
    "        \"       FIRST(v.attr) AS attr,\" +\n",
    "        \"       COUNT(*) AS outdegree \" +\n",
    "        \"FROM   v \" +\n",
    "        \"JOIN   e \" +\n",
    "        \"  ON   v.id=e.src \" +\n",
    "        \"GROUP BY v.id\").cache,\n",
    "      in.edges)\n",
    "\n",
    "    val absent = in2.find(\"(v1)-[]->(v2); (v2)-[]->(v3); !(v1)-[]->(v3)\")\n",
    "    absent.createOrReplaceTempView(\"a\")\n",
    "\n",
    "    val present = in2.find(\"(v1)-[]->(v2); (v2)-[]->(v3); (v1)-[]->(v3)\")\n",
    "    present.createOrReplaceTempView(\"p\")\n",
    "\n",
    "    absent.sqlContext.sql(\n",
    "      \"SELECT v1 an,\" +\n",
    "        \"       SUM(v1.outdegree * v2.outdegree * v3.outdegree) AS ac \" +\n",
    "        \"FROM   a \" +\n",
    "        \"GROUP BY v1\").createOrReplaceTempView(\"aa\")\n",
    "\n",
    "    present.sqlContext.sql(\n",
    "      \"SELECT v1 pn,\" +\n",
    "        \"       SUM(v1.outdegree * v2.outdegree * v3.outdegree) AS pc \" +\n",
    "        \"FROM   p \" +\n",
    "        \"GROUP BY v1\").createOrReplaceTempView(\"pa\")\n",
    "\n",
    "    absent.sqlContext.sql(\"SELECT an,\" +\n",
    "      \"       ac * pc/(ac+pc) AS score \" +\n",
    "      \"FROM   aa \" +\n",
    "      \"JOIN   pa\" +\n",
    "      \"  ON   an=pn \" +\n",
    "      \"ORDER BY score DESC\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
